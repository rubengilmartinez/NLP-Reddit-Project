{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqp068oPXCvt"
      },
      "source": [
        "# **Aplicación PLN para análisis y procesamiento de texto de carácter geopolítico, económico y político.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1) COMPILACIÓN DEL CORPUS DE COMENTARIOS DE REDDIT A TRAVÉS DE SU API:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LIBRERÍAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6y8sMCKPXBD4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "import datetime as dt\n",
        "import time\n",
        "\n",
        "import praw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWYnXHXXCjm"
      },
      "source": [
        "**Primero de todo, extraeremos el corpus de documentos creando una aplicación para conectarnos a la API de Reddit y así poder extraer los datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Nombre de usuario: Solid_Valuable_2275\n",
        "- Clave: \tiDAtL0KxYY9ky4GyPWyUM2OAZ4LnBg\n",
        "- ID usuario: v4Ozy7so3ZR5n-i4r7Spqw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuración de credenciales\n",
        "reddit = praw.Reddit(\n",
        "    client_id='v4Ozy7so3ZR5n-i4r7Spqw',\n",
        "    client_secret='iDAtL0KxYY9ky4GyPWyUM2OAZ4LnBg',\n",
        "    user_agent='dl-pln-2025-RGM-GLP',\n",
        "    username='Solid_Valuable_2275',\n",
        "    password='ABCdef12345%' \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error de autenticación: OAuthException - invalid_grant error processing request\n",
            "Por favor, verifica tus credenciales y la configuración de la aplicación.\n"
          ]
        }
      ],
      "source": [
        "import praw\n",
        "import time\n",
        "\n",
        "\n",
        "# Prueba simple de autenticación\n",
        "try:\n",
        "    # Intenta acceder a tu nombre de usuario para verificar autenticación\n",
        "    print(f\"Autenticado como: {reddit.user.me()}\")\n",
        "    \n",
        "    # Prueba una solicitud simple\n",
        "    for submission in reddit.subreddit(\"test\").hot(limit=1):\n",
        "        print(f\"Título del post de prueba: {submission.title}\")\n",
        "        \n",
        "    print(\"¡Autenticación exitosa!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error de autenticación: {type(e).__name__} - {str(e)}\")\n",
        "    print(\"Por favor, verifica tus credenciales y la configuración de la aplicación.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando subreddit: Economics.....\n",
            "  Extrayendo de Economics con filtro temporal: day\n",
            "Error en Economics con filtro day: invalid_grant error processing request\n",
            "  Extrayendo de Economics con filtro temporal: week\n",
            "Error en Economics con filtro week: invalid_grant error processing request\n",
            "  Extrayendo de Economics con filtro temporal: month\n",
            "Error en Economics con filtro month: invalid_grant error processing request\n",
            "  Extrayendo de Economics con filtro temporal: year\n",
            "Error en Economics con filtro year: invalid_grant error processing request\n",
            "  Extrayendo de Economics con filtro temporal: all\n",
            "Error en Economics con filtro all: invalid_grant error processing request\n",
            "Procesando subreddit: investing.....\n",
            "  Extrayendo de investing con filtro temporal: day\n",
            "Error en investing con filtro day: invalid_grant error processing request\n",
            "  Extrayendo de investing con filtro temporal: week\n",
            "Error en investing con filtro week: invalid_grant error processing request\n",
            "  Extrayendo de investing con filtro temporal: month\n",
            "Error en investing con filtro month: invalid_grant error processing request\n",
            "  Extrayendo de investing con filtro temporal: year\n",
            "Error en investing con filtro year: invalid_grant error processing request\n",
            "  Extrayendo de investing con filtro temporal: all\n",
            "Error en investing con filtro all: invalid_grant error processing request\n",
            "Procesando subreddit: geopolitics.....\n",
            "  Extrayendo de geopolitics con filtro temporal: day\n",
            "Error en geopolitics con filtro day: invalid_grant error processing request\n",
            "  Extrayendo de geopolitics con filtro temporal: week\n",
            "Error en geopolitics con filtro week: invalid_grant error processing request\n",
            "  Extrayendo de geopolitics con filtro temporal: month\n",
            "Error en geopolitics con filtro month: invalid_grant error processing request\n",
            "  Extrayendo de geopolitics con filtro temporal: year\n",
            "Error en geopolitics con filtro year: invalid_grant error processing request\n",
            "  Extrayendo de geopolitics con filtro temporal: all\n",
            "Error en geopolitics con filtro all: invalid_grant error processing request\n",
            "Procesando subreddit: stocks.....\n",
            "  Extrayendo de stocks con filtro temporal: day\n",
            "Error en stocks con filtro day: invalid_grant error processing request\n",
            "  Extrayendo de stocks con filtro temporal: week\n",
            "Error en stocks con filtro week: invalid_grant error processing request\n",
            "  Extrayendo de stocks con filtro temporal: month\n",
            "Error en stocks con filtro month: invalid_grant error processing request\n",
            "  Extrayendo de stocks con filtro temporal: year\n",
            "Error en stocks con filtro year: invalid_grant error processing request\n",
            "  Extrayendo de stocks con filtro temporal: all\n",
            "Error en stocks con filtro all: invalid_grant error processing request\n",
            "Procesando subreddit: CryptoCurrency.....\n",
            "  Extrayendo de CryptoCurrency con filtro temporal: day\n",
            "Error en CryptoCurrency con filtro day: invalid_grant error processing request\n",
            "  Extrayendo de CryptoCurrency con filtro temporal: week\n",
            "Error en CryptoCurrency con filtro week: invalid_grant error processing request\n",
            "  Extrayendo de CryptoCurrency con filtro temporal: month\n",
            "Error en CryptoCurrency con filtro month: invalid_grant error processing request\n",
            "  Extrayendo de CryptoCurrency con filtro temporal: year\n",
            "Error en CryptoCurrency con filtro year: invalid_grant error processing request\n",
            "  Extrayendo de CryptoCurrency con filtro temporal: all\n",
            "Error en CryptoCurrency con filtro all: invalid_grant error processing request\n",
            "Procesando subreddit: business.....\n",
            "  Extrayendo de business con filtro temporal: day\n",
            "Error en business con filtro day: invalid_grant error processing request\n",
            "  Extrayendo de business con filtro temporal: week\n",
            "Error en business con filtro week: invalid_grant error processing request\n",
            "  Extrayendo de business con filtro temporal: month\n",
            "Error en business con filtro month: invalid_grant error processing request\n",
            "  Extrayendo de business con filtro temporal: year\n",
            "Error en business con filtro year: invalid_grant error processing request\n",
            "  Extrayendo de business con filtro temporal: all\n",
            "Error en business con filtro all: invalid_grant error processing request\n"
          ]
        }
      ],
      "source": [
        "# Lista de subreddits a extraer\n",
        "subreddits = ['Economics', 'investing', 'geopolitics', 'stocks', 'CryptoCurrency', 'business' ]\n",
        "\n",
        "\n",
        "\n",
        "# Funciones de procesamiento de comentarios:\n",
        "\n",
        "# Función para verificar si un texto es válido\n",
        "def is_valid_comment(text):\n",
        "    # Verificar longitud mínima (por ejemplo, 50 caracteres)\n",
        "    if len(text) < 50:\n",
        "        return False\n",
        "    \n",
        "    \n",
        "    # Verificar si solo contiene URLs o emails\n",
        "    url_pattern = re.compile(r'(https?://\\S+)')\n",
        "    email_pattern = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
        "    \n",
        "    # Reemplazar URLs y emails con espacios\n",
        "    text_without_urls = url_pattern.sub(' ', text)\n",
        "    text_without_emails = email_pattern.sub(' ', text_without_urls)\n",
        "    \n",
        "    # Eliminar espacios múltiples y verificar contenido restante\n",
        "    cleaned_text = ' '.join(text_without_emails.split())\n",
        "    \n",
        "    # Si queda poco texto después de eliminar URLs y emails, rechazar\n",
        "    if len(cleaned_text) < 30:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Para cada subreddit\n",
        "for subreddit_name in subreddits:\n",
        "    print(f\"Procesando subreddit: {subreddit_name}.....\")\n",
        "    \n",
        "    # Estructura para este subreddit\n",
        "    subreddit_data = {\n",
        "        \"subreddit_name\": subreddit_name,\n",
        "        \"threads\": []\n",
        "    }\n",
        "    \n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    \n",
        "    # Obtener hilos de diferentes períodos temporales para asegurar diversidad\n",
        "    time_filters = ['day', 'week', 'month', 'year', 'all']\n",
        "    threads_collected = 0\n",
        "    \n",
        "    for time_filter in time_filters:\n",
        "        if threads_collected >= 20:\n",
        "            break\n",
        "            \n",
        "        # Calcular cuántos hilos necesitamos de este filtro\n",
        "        threads_needed = min(4, 20 - threads_collected)\n",
        "        \n",
        "        if threads_needed <= 0:\n",
        "            continue\n",
        "            \n",
        "        print(f\"  Extrayendo de {subreddit_name} con filtro temporal: {time_filter}\")\n",
        "        \n",
        "        try:\n",
        "            threads = list(subreddit.top(time_filter=time_filter, limit=threads_needed))\n",
        "            \n",
        "            for thread in threads:\n",
        "                if threads_collected >= 20:\n",
        "                    break\n",
        "                    \n",
        "                print(f\"    Procesando hilo: {thread.title[:30]}...\")\n",
        "                \n",
        "                # Información del hilo\n",
        "                thread_info = {\n",
        "                    \"thread_id\": thread.id,\n",
        "                    \"title\": thread.title,\n",
        "                    \"author\": str(thread.author),\n",
        "                    \"created_utc\": datetime.fromtimestamp(thread.created_utc).isoformat(),\n",
        "                    \"score\": thread.score,\n",
        "                    \"url\": thread.url,\n",
        "                    \"permalink\": thread.permalink,\n",
        "                    \"time_filter\": time_filter,\n",
        "                    \"comments\": []\n",
        "                }\n",
        "                \n",
        "                # Expandir todos los comentarios\n",
        "                thread.comments.replace_more(limit=None)\n",
        "                \n",
        "                # Obtener comentarios planos\n",
        "                flat_comments = thread.comments.list()\n",
        "                \n",
        "                # Contador para este hilo\n",
        "                valid_comments_count = 0\n",
        "                \n",
        "                for comment in flat_comments:\n",
        "                    # Verificar si el comentario es válido\n",
        "                    if is_valid_comment(comment.body):\n",
        "\n",
        "                        # Extraer información relevante\n",
        "                        comment_info = {\n",
        "                            'comment_id': comment.id,\n",
        "                            'author': str(comment.author),\n",
        "                            'text': comment.body,\n",
        "                            'score': comment.score,\n",
        "                            'created_utc': datetime.fromtimestamp(comment.created_utc).isoformat(),\n",
        "                            'is_submitter': comment.is_submitter,\n",
        "                            'permalink': comment.permalink\n",
        "                        }\n",
        "                        \n",
        "                        thread_info[\"comments\"].append(comment_info)\n",
        "                        valid_comments_count += 1\n",
        "                        \n",
        "                        # Limitar a 50 comentarios válidos por hilo\n",
        "                        if valid_comments_count >= 50:\n",
        "                            break\n",
        "                \n",
        "                # Solo añadir hilos con suficientes comentarios válidos\n",
        "                if valid_comments_count >= 25:  # Mínimo 25 comentarios válidos\n",
        "                    subreddit_data[\"threads\"].append(thread_info)\n",
        "                    threads_collected += 1\n",
        "                    print(f\"      Añadido con {valid_comments_count} comentarios válidos\")\n",
        "                else:\n",
        "                    print(f\"      Descartado: solo {valid_comments_count} comentarios válidos\")\n",
        "                \n",
        "                # Pausa para respetar límites de la API\n",
        "                time.sleep(2)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Error en {subreddit_name} con filtro {time_filter}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    # Guardar datos de este subreddit en un archivo JSON\n",
        "    output_file = os.path.join(output_dir, f\"{subreddit_name}_data.json\")\n",
        "    \n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(subreddit_data, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"Completado: {subreddit_name} - {threads_collected} hilos guardados en {output_file}\")\n",
        "\n",
        "print(\"Extracción completa.\")'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'subreddit_name': 'business', 'threads': []}\n"
          ]
        }
      ],
      "source": [
        "print(subreddit_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verificación de comentarios válidos\n",
        "Distribución temporal diversa\n",
        "Descarte de hilos con pocos comentarios válidos\n",
        "\n",
        "\n",
        "\n",
        "Pausas para respetar límites de la API\n",
        "Manejo de excepciones para evitar interrupciones\n",
        "Seguimiento del progreso mediante mensajes"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM7WT3JKuGij/JurAfV1xur",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLP_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
